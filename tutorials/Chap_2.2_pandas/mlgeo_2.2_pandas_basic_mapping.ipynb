{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a438f0",
   "metadata": {},
   "source": [
    "# 2.2 Pandas, Basic Mapping\n",
    "\n",
    "This section aims to provide new skills in python to handle structured \"table\" data. \n",
    "\n",
    "Learning outcome:\n",
    "-   Manipulation of data frames (describing, filtering, ...) \n",
    "-   Learn about Lambda functions\n",
    "-   Intro to datetime objects\n",
    "-   Plotting data from data frames (histograms and maps)\n",
    "-   Introduction to Plotly\n",
    "-   Introduction to CSV & Parquet\n",
    "\n",
    "\n",
    "We will work on several structured data sets: sensor metadata, seismic data product (earthquake catalog).\n",
    "\n",
    "First, we import all the modules we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'vscode' # writes as standalone html, \n",
    "# try notebook, jupyterlab, png, vscode, iframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc6849",
   "metadata": {},
   "source": [
    "## Creating a data frame from standard text files\n",
    "\n",
    "The python package pandas is very useful to read csv files, but also many text files that are more or less formated as one observation per row and one column for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2662f",
   "metadata": {},
   "source": [
    "As an example, we are going to look at the list of seismic stations from the Northern California seismic network, available [here](http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3737498",
   "metadata": {},
   "source": [
    "The function read_csv is used to open and read your text file. In the case of a well formatted csv file, only the name of the file needs to be entered:\n",
    "\n",
    "     data = pd.read_csv('my_file.csv')\n",
    "\n",
    "However, many options are available if the file is not well formatted. See more in this [tutorial](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets the file linked in the URL page and convert it to a string\n",
    "s = requests.get(url).content \n",
    "# this will convert the string, decode it , and make it a table\n",
    "data = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None, skiprows=2, sep='\\s+', usecols=list(range(0, 13)))\n",
    "# because columns/keys were not assigned, assign them now\n",
    "data.columns = ['station', 'network', 'channel', 'location', 'rate', 'start_time', 'end_time', 'latitude', 'longitude', 'elevation', 'depth', 'dip', 'azimuth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a04924",
   "metadata": {},
   "source": [
    "Let us look at the data. They are now stored into a pandas dataframe. Read the top of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39168b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32624494",
   "metadata": {},
   "source": [
    "There are two aways of looking at a particular column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or like this:\n",
    "data['station']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896206be",
   "metadata": {},
   "source": [
    "If we want to look at a given row or column, and we know its index, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28662a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7799bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb482fa2",
   "metadata": {},
   "source": [
    "If we know the name of the column, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'station']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0a1df",
   "metadata": {},
   "source": [
    "We can also access a single value within a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aca87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[0, 'station']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23510633",
   "metadata": {},
   "source": [
    "## Mapping usiny Plotly\n",
    "\n",
    "Now we will plot the station locations on a map using the Plotly package. More tutorials on [Plotly](https://plotly.com/). Input of the function in the function is self-explanatory and typical of Python's function. The code [documentation](https://plotly.com/python/scatter-plots-on-maps/) of Plotly scatter_geo lists the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf74a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(data,\n",
    "                     lat='latitude',lon='longitude', \n",
    "                     range_color=(6,9),\n",
    "                     height=800, width=800,\n",
    "                     hover_name=\"station\",\n",
    "                     hover_data=['network','station','channel','rate']);\n",
    "fig.update_geos(resolution=110, showcountries=True,projection_type=\"orthographic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fdd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(data,\n",
    "                     lat='latitude',lon='longitude', \n",
    "                     range_color=(6,9),mapbox_style=\"carto-positron\",\n",
    "                     height=800, width=800,\n",
    "                     hover_name=\"station\",\n",
    "                     hover_data=['network','station','channel','rate']);\n",
    "fig.update_layout(title=\"Northern California Seismic Network\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991c460",
   "metadata": {},
   "source": [
    "## Pandas: data selection\n",
    "We can filter the data with the value taken by a given column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.station=='KCPB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38240e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two stations\n",
    "data.loc[(data.station=='KCPB') | (data.station=='KHBB')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or like this\n",
    "data.loc[data.station.isin(['KCPB', 'KHBB'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cf1c9",
   "metadata": {},
   "source": [
    "We can access to a brief summary of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86eb768",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.station.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1aed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.elevation.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e821e4",
   "metadata": {},
   "source": [
    "We can perform standard operations on the whole data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f17636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dea1f",
   "metadata": {},
   "source": [
    "In the case of a categorical variable, we can get the list of possile values that this variable can take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.channel.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750a7ec",
   "metadata": {},
   "source": [
    "and get the number of times that each value is taken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50049411",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.station.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec19797",
   "metadata": {},
   "source": [
    "There are several ways of doing an operation on all rows of a column. The first option is to use the map function.\n",
    "\n",
    "If you are not familiar with lambda function in Python, look at:\n",
    "\n",
    "https://realpython.com/python-lambda/\n",
    "\n",
    "We will practice a bit lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e198ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to return the difference between the input and a value\n",
    "\n",
    "b = 1 # b is declared outside of a function and is a GLOBAL variable\n",
    "\n",
    "def remove_elevation(x):\n",
    "    return x-b\n",
    "print(remove_elevation(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a06f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are creating a function with a local variable\n",
    "def remove_elevation2(x):\n",
    "    b2=2 # b is now declared inside the function, is LOCAL, and cannot be called outside.\n",
    "    return x-b2\n",
    "print(remove_elevation2(3))\n",
    "# print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the equivalent in lambda is:\n",
    "remove_b = lambda x:x-b\n",
    " # b was defined above so it is a parameter. x is the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_b(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24982f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add several variables into lambda functions\n",
    "remove_anything = lambda x,y:x-y\n",
    "remove_anything(3,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_elevation_mean = data.elevation.mean()\n",
    "data.elevation.map(lambda p: p - data_elevation_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f2364",
   "metadata": {},
   "source": [
    "The second option is to use the apply function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remean_elevation(row):\n",
    "    row.elevation = row.elevation - data_elevation_mean\n",
    "    return row\n",
    "data.apply(remean_elevation, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfaf7a3",
   "metadata": {},
   "source": [
    "We can also carry out simple operations on columns, provided they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "netsta=(data.network + '.' + data.station)\n",
    "print(netsta)\n",
    "print(type(netsta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "netsta=(data.network + '.' + data.station).values\n",
    "print(netsta)\n",
    "print(type(netsta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4800d2",
   "metadata": {},
   "source": [
    "A useful feature is to group the rows depending on the value of a categorical variable, and then apply the same operation to all the groups. For instance, we want to know how many times each station appears in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb628370",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('station').station.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269dc15e",
   "metadata": {},
   "source": [
    "Or we want to know what is the lowest and the highest elevation for each station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('station').elevation.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104a322",
   "metadata": {},
   "source": [
    "We can have access to the data type of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2becd",
   "metadata": {},
   "source": [
    "Here, pandas does not recognize the start_time and end_time columns as a datetime format, so we cannot use datetime operations on them. We first need to convert these columns into a datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aceba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.start_time.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['start_time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform column from string into datetime format\n",
    "startdate = pd.to_datetime(data['start_time'], format='%Y/%m/%d,%H:%M:%S')\n",
    "data['start_time'] = startdate\n",
    "print(data['start_time'] )\n",
    "type(data['start_time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for end times\n",
    "# Avoid 'OutOfBoundsDatetime' error with year 3000\n",
    "enddate = data['end_time'].str.replace('3000', '2025')\n",
    "enddate = pd.to_datetime(enddate, format='%Y/%m/%d,%H:%M:%S')\n",
    "data['end_time'] = enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396171f",
   "metadata": {},
   "source": [
    "⚠️ Advanced exercise: You may notice that some stations have a latitude and longitude of zero. Clean up the data frame and report it to the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your answers here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe088ce",
   "metadata": {},
   "source": [
    "We can now look when each seismic station was installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('station').apply(lambda df: df.start_time.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107f1b9",
   "metadata": {},
   "source": [
    "The ``agg`` function allows to carry out several operations to each group of rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86283e",
   "metadata": {},
   "source": [
    "Select the stations that were deployed first and recovered last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fe517",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['station']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8509ce2",
   "metadata": {},
   "source": [
    "We can also make groups by selecting the values of two categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['station', 'channel']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5c978",
   "metadata": {},
   "source": [
    "Previously, we just printed the output, but we can also store it in a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.groupby(['station', 'channel']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77003692",
   "metadata": {},
   "source": [
    "Print the new dataframe and look at the rows indexes. Anything wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ceaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454126d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21a14e87",
   "metadata": {},
   "source": [
    "When we select only some rows, the index is not automatically reset to start at 0. We can do it manually. Many functions in pandas have also an option to reset the index, and option to transform the dataframe in place, instead of saving the results in another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e91221",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c76c3",
   "metadata": {},
   "source": [
    "It is also possible to sort the dataset by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.sort_values(by='start_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdcd7c",
   "metadata": {},
   "source": [
    "We can apply the sorting to several columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped.sort_values(by=['start_time', 'end_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553cccfe",
   "metadata": {},
   "source": [
    "The ``merge`` function allows to merge two dataframes that have some but not all columns in common.\n",
    "\n",
    "\n",
    "Now, we are going to merge this seismic metadata frame to the one from the Pacific Northwest Seismic Network and other stations that were deployed in the area. The file is a CSV file. Read the file and describe the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfde5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter response here\n",
    "data_pnw=pd.read_csv('PNSN_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abef0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pnw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92398f",
   "metadata": {},
   "source": [
    "You will notice that this file contains odd times for starttime and end times. The keys are also different from the previous dataframe. In order to compare them and concatenate both metadata, we want to at least have common keys.\n",
    "\n",
    "First, make sure that both dataframes have common keys. Use the function [``rename``](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) from ``pandas`` to rename the keys in data_pnw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e150e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter answer below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e46c2",
   "metadata": {},
   "source": [
    "Then convert the time stamps of start_time and end_time into date time objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3bf3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work together (i could not fix it!)\n",
    "\n",
    "# L=len(data_pnw['starttime'])\n",
    "# newdt = np.ndarray(L,dtype=np.datetime64)\n",
    "# for icrap in range(len(data_pnw['starttime'])):\n",
    "#     print(icrap)\n",
    "#     print(type(data_pnw['starttime'][icrap]))\n",
    "#     print(data_pnw['starttime'][icrap])\n",
    "#     newdt[icrap]= datetime.fromtimestamp(data_pnw['starttime'][icrap])\n",
    "# print(newdt)\n",
    "# print(data_pnw.starttime)\n",
    "\n",
    "# startdate = pd.to_timedelta(data_pnw['starttime'])\n",
    "# startdate = pd.to_timedelta(datetime.fromtimestamp(data_pnw.starttime), format='%Y/%m/%d,%H:%M:%S')\n",
    "# print(startdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19907b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data,data_pnw],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c86fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earthquakes in filtered 2007-2009 catalog but not in (unfiltered) 2004-2011 catalog\n",
    "df_all = pd.concat([df2, df1_filter], ignore_index=True)\n",
    "df_merge = df_all.merge(df2.drop_duplicates(), on=['date'], how='left', indicator=True)\n",
    "df_added_1 = df_merge[df_merge['_merge'] == 'left_only']\n",
    "\n",
    "# Earthquakes in filtered 2004-2011 catalog but not in (unfiltered) 2007-2009 catalog\n",
    "df_all = pd.concat([df1, df2_filter], ignore_index=True)\n",
    "df_merge = df_all.merge(df1.drop_duplicates(), on=['date'], how='left', indicator=True)\n",
    "df_added_2 = df_merge[df_merge['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf81d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e936cf31",
   "metadata": {},
   "source": [
    "### Overview of Earthquake catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbb681",
   "metadata": {},
   "outputs": [],
   "source": [
    "quake=pd.read_csv('Global_Quakes_IRIS.csv')\n",
    "quake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e23a6",
   "metadata": {},
   "source": [
    "* Plot the earthquakes using Plotly functionality.\n",
    "\n",
    "Use \"description\" as a hover name. \n",
    "\n",
    "Use \"marker_size\" for size and color the markers using the key 'magnitude'.\n",
    "\n",
    "Use \"magnitude\" and \"depth\" as hover data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c710ec",
   "metadata": {},
   "source": [
    "Using ``matplotlib``, make a histogram of the magnitude distribution of these earthquakes. Find a way to plot the y-axis in log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a050f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('madrona')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c2df93b363d800c8a9b94963221f1be1d8deaf6a76f83b6b9a486ad05d69583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
